# GeoSpatial-RAG: An AI Framework For Analysis Of Remote Sensing Images

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://streamlit.io)

A novel AI framework designed specifically for the analysis of remote sensing images, integrating large language models (LLMs) with specialized vision-language models to overcome challenges in Earth observation data analysis.

![GeoSpatial-RAG Demo](https://via.placeholder.com/800x400/1e3c72/ffffff?text=GeoSpatial-RAG+Framework)

## ğŸŒ Overview

GeoSpatial-RAG employs a retrieval-augmented generation (RAG) approach that creates a multi-modal knowledge vector database from remote sensing imagery and textual descriptions. The framework addresses the significant domain gap between natural images and remote sensing imagery by developing a specialized pipeline using CLIP (Contrastive Language-Image Pretraining).

### ğŸ¯ Key Innovation
- **Domain-Specific RAG**: First RAG system specifically designed for remote sensing imagery
- **Multi-Modal Intelligence**: Seamlessly combines text and image understanding
- **High Accuracy**: Achieves 88%+ similarity matching for relevant queries
- **Production Ready**: Complete web interface with ChatGPT-like experience

## âœ¨ Key Features

- ğŸ§  **Multi-modal Knowledge Vector Database**: Unified encoding of remote sensing images and text descriptions
- ğŸ” **Cross-modal Retrieval**: Semantic search using natural language queries or image inputs
- ğŸ¯ **CLIP-based Embeddings**: Leverages CLIP for both visual and textual information encoding
- ğŸ¤– **LangChain Integration**: Advanced text generation with vision-language model support
- ğŸ—ƒï¸ **SQLite Database**: Efficient storage and retrieval of embeddings
- ğŸŒ **Web Interface**: Modern ChatGPT-like interface for easy interaction
- âš¡ **Real-time Processing**: GPU-accelerated processing for fast responses

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Input Query   â”‚    â”‚     Images      â”‚    â”‚  Text Captions  â”‚
â”‚   (Text/Image)  â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                      â”‚                      â”‚
          â–¼                      â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CLIP Encoder                                 â”‚
â”‚                (Text + Vision)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                SQLite Vector Database                           â”‚
â”‚            (Text & Image Embeddings)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Similarity Search & Retrieval                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        LangChain RAG Pipeline + VLM Generation                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Generated Response                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- CUDA-compatible GPU (recommended)
- 8GB+ RAM

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/debanjan06/geospatial-rag.git
cd geospatial-rag
```

2. **Create virtual environment**
```bash
python -m venv geospatial_env

# Windows
geospatial_env\Scripts\activate

# Linux/MacOS
source geospatial_env/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
pip install -e .
```

4. **Set up environment variables**
```bash
cp .env.example .env
# Edit .env with your configuration
```

### ğŸ—ƒï¸ Database Setup

#### Option 1: Use Pre-built Database (Recommended for Testing)
```bash
# Download our pre-built database (10,975 documents)
# Place in: database/rsicd_embeddings.db
# Contact: bl.sc.p2dsc24032@bl.students.amrita.edu for access
```

#### Option 2: Create Your Own Database
```bash
# 1. Download RSICD dataset
wget [RSICD_DATASET_URL]

# 2. Generate embeddings
python scripts/generate_embeddings.py --dataset_path /path/to/RSICD --output_dir ./database

# 3. Create SQLite database
python scripts/create_database.py --embeddings_dir ./database --db_path ./database/rsicd_embeddings.db
```

#### Option 3: Demo Database (Quick Testing)
```bash
# Create a small demo database for testing
python scripts/create_demo_database.py
```

### ğŸ§ª Test Your Setup

```bash
# Test database and imports
python test_database.py
```

Expected output:
```
ğŸš€ GeoSpatial-RAG System Test
========================================
âœ… Database connected successfully!
   ğŸ“Š Descriptions: 10,975
   ğŸ“ Text embeddings: 10,975
   ğŸ–¼ï¸ Image embeddings: 10,975
âœ… All tests passed!
```

## ğŸ”§ Usage

### Command Line Interface

```bash
# Interactive demo
python demo/interactive_demo.py --db_path ./database/rsicd_embeddings.db
```

### Web Interface (Recommended)

```bash
# Start the web interface
streamlit run streamlit_app.py
```

Then open: http://localhost:8501

### Python API

```python
from geospatial_rag import GeoSpatialRAG
from PIL import Image

# Initialize the RAG system
rag = GeoSpatialRAG(db_path="./database/rsicd_embeddings.db")

# Text-only query
results = rag.query("Show me aerial views of storage tanks")

# Text + Image query
image = Image.open("satellite_image.jpg")
results = rag.query("What does this image show?", image=image)

# Display results
for doc in results['documents']:
    print(f"Description: {doc.page_content}")
    print(f"Similarity: {doc.metadata['similarity']:.4f}")
    print("---")

print(f"AI Response: {results['response']}")

# Close when done
rag.close()
```

## ğŸ“Š Performance Results

Our system has been tested and validated with impressive results:

- **ğŸ“Š Database Size**: 10,975 remote sensing images with embeddings
- **ğŸ¯ Accuracy**: 88%+ similarity scores for relevant queries
- **âš¡ Speed**: <2 seconds average query time on GPU
- **ğŸ” Precision**: High relevance in top-5 results for domain-specific queries

### Example Query Results

| Query | Top Similarity Score | Retrieved Documents | Response Quality |
|-------|---------------------|-------------------|------------------|
| "industrial complex with buildings" | 0.8818 | 5/5 relevant | Excellent |
| "aerial view of storage tanks" | 0.7631 | 5/5 relevant | Excellent |
| "satellite image of urban area" | 0.8203 | 4/5 relevant | Very Good |
| "remote sensing of forest" | 0.7892 | 5/5 relevant | Excellent |

## ğŸ“ Project Structure

```
geospatial-rag/
â”œâ”€â”€ src/geospatial_rag/           # Main package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ embeddings.py             # CLIP embedding generation
â”‚   â”œâ”€â”€ database.py               # SQLite database operations
â”‚   â”œâ”€â”€ retriever.py              # Custom retriever class
â”‚   â”œâ”€â”€ pipeline.py               # Main RAG pipeline
â”‚   â”œâ”€â”€ utils.py                  # Utility functions
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ vlm_models.py         # Vision-language models
â”œâ”€â”€ demo/
â”‚   â””â”€â”€ interactive_demo.py       # Command-line interface
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_embeddings.py    # Data preprocessing
â”‚   â””â”€â”€ create_database.py        # Database creation
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ examples/                 # Example notebooks
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_embeddings.py
â”‚   â”œâ”€â”€ test_database.py
â”‚   â””â”€â”€ test_pipeline.py
â”œâ”€â”€ docs/                         # Documentation
â”œâ”€â”€ streamlit_app.py              # Web interface
â”œâ”€â”€ requirements.txt              # Dependencies
â”œâ”€â”€ setup.py                      # Package setup
â”œâ”€â”€ .env.example                  # Configuration template
â””â”€â”€ README.md                     # This file
```

## ğŸŒ Web Interface Features

The Streamlit web interface provides:

- ğŸ’¬ **ChatGPT-like Interface**: Natural conversation flow
- ğŸ–¼ï¸ **Image Upload**: Drag-and-drop satellite/aerial image analysis
- âš™ï¸ **Advanced Settings**: Configurable similarity thresholds and result counts
- ğŸ“Š **Real-time Stats**: Database statistics and system status
- ğŸ” **Live Search**: Instant results with similarity scores
- ğŸ“± **Responsive Design**: Works on desktop and mobile

## ğŸ› ï¸ Configuration

### Environment Variables (.env)

```bash
# Model Configuration
CLIP_MODEL_NAME=openai/clip-vit-base-patch32
VLM_MODEL_NAME=Salesforce/blip-image-captioning-large
DEVICE=auto

# Database Configuration
DB_PATH=./database/rsicd_embeddings.db

# Processing Configuration
BATCH_SIZE=16
TEXT_WEIGHT=0.7
IMAGE_WEIGHT=0.3
TOP_K=5

# API Keys (optional)
HUGGINGFACE_API_KEY=your_hf_api_key_here
```

### Advanced Configuration

The system supports extensive configuration through:
- Environment variables
- Configuration files (JSON/YAML)
- Command-line arguments
- Python API parameters

## ğŸ“ˆ Dataset Information

### RSICD Dataset
- **Size**: 10,921 remote sensing images
- **Resolution**: 224Ã—224 pixels
- **Sources**: Google Earth, Baidu Map, MapABC, Tianditu
- **Descriptions**: 5 sentences per image
- **Splits**: Train (8,734) / Valid (1,094) / Test (1,093)
- **Features**: High intra-class diversity and low inter-class dissimilarity

### Supported Image Types
- Satellite imagery
- Aerial photography
- Remote sensing data
- Multispectral images
- Urban planning imagery
- Agricultural monitoring
- Environmental surveillance

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/ -v

# Run specific test modules
pytest tests/test_embeddings.py
pytest tests/test_database.py
pytest tests/test_pipeline.py

# Run with coverage
pytest tests/ --cov=geospatial_rag --cov-report=html
```

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md).

### Development Setup

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Install development dependencies: `pip install -e ".[dev]"`
4. Make your changes and add tests
5. Run tests: `pytest tests/`
6. Submit a pull request

### Areas for Contribution

- ğŸ”¬ **New Models**: Integration of additional vision-language models
- ğŸ“Š **Datasets**: Support for new remote sensing datasets
- ğŸŒ **Interfaces**: Mobile apps, desktop applications
- ğŸš€ **Performance**: Optimization and scaling improvements
- ğŸ“š **Documentation**: Tutorials, examples, and guides

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“– Citation

If you use this work in your research, please cite:

```bibtex
@article{shil2024geospatial,
  title={GeoSpatial-RAG: An AI Framework For Analysis Of Remote Sensing Images},
  author={Shil, Debanjan and Bhattacharya, Partha Priya and Gupta, Deepa},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2024},
  publisher={IEEE}
}
```

## ğŸ”— Related Work & References

- **CLIP**: [Learning Transferable Visual Representations](https://arxiv.org/abs/2103.00020)
- **BLIP**: [Bootstrapping Language-Image Pre-training](https://arxiv.org/abs/2201.12086)
- **LangChain**: [Building applications with LLMs](https://github.com/langchain-ai/langchain)
- **RSICD Dataset**: [Exploring Models and Data for Remote Sensing Image Caption Generation](https://github.com/201528014227051/RSICD_optimal)

## ğŸ† Acknowledgments

- **Amrita Viswa Vidyapeetham** for research support and computational resources
- **OpenAI** for the CLIP model and vision-language research
- **Salesforce** for the BLIP model
- **RSICD dataset creators** for providing the remote sensing image captioning dataset
- **LangChain community** for the RAG framework
- **Streamlit team** for the excellent web app framework

## ğŸ“ Contact & Support

- **Lead Researcher**: Debanjan Shil
- **Email**: [bl.sc.p2dsc24032@bl.students.amrita.edu](mailto:bl.sc.p2dsc24032@bl.students.amrita.edu)
- **Institution**: School of Computing, Amrita Viswa Vidyapeetham, Bengaluru
- **Project Repository**: [https://github.com/debanjan06/geospatial-rag](https://github.com/debanjan06/geospatial-rag)

### Getting Help

- ğŸ› **Bug Reports**: [GitHub Issues](https://github.com/debanjan06/geospatial-rag/issues)
- ğŸ’¡ **Feature Requests**: [GitHub Discussions](https://github.com/debanjan06/geospatial-rag/discussions)
- ğŸ“§ **Direct Contact**: For database access or collaboration inquiries
- ğŸ“š **Documentation**: Check our [docs/](docs/) directory for detailed guides

## ğŸŒŸ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=debanjan06/geospatial-rag&type=Date)](https://star-history.com/#debanjan06/geospatial-rag&Date)

---

<div align="center">

**â­ Star this repository if you find it helpful!**

**ğŸš€ Ready to revolutionize remote sensing analysis with AI?**

[Get Started](https://github.com/debanjan06/geospatial-rag) â€¢ [Documentation](docs/) â€¢ [Examples](notebooks/) â€¢ [Web Demo](streamlit_app.py)

</div>
